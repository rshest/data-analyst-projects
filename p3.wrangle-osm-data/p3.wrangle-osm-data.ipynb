{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3. Wrangle Open Street Map Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "<img style=\"float: center;\" src=\"img/logo.png\">\n",
    "\n",
    "\n",
    "I chose the area of Oslo, the capital of Norway. The snapshot of it can be downloaded from [mapzen](https://s3.amazonaws.com/metro-extracts.mapzen.com/oslo_norway.osm.bz2).\n",
    "\n",
    "There is a makefile in this folder, which does the download and unpacks the file for the whole dataset:\n",
    "\n",
    "```bash\n",
    "$ make download\n",
    "```\n",
    "\n",
    "Note that it's a big file (1.3Gb). There is a smaller sample included for testing, `stovner.osm`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.CodeCell.config_defaults.highlight_modes['magic_sql'] = {'reg':[/^%%sql/]};"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the ipython-sql extention to run inline SQL and setup syntax coloring for it\n",
    "%load_ext sql\n",
    "\n",
    "import IPython\n",
    "js = \"IPython.CodeCell.config_defaults.highlight_modes['magic_sql'] = {'reg':[/^%%sql/]};\"\n",
    "IPython.core.display.display_javascript(js, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: None@oslo_norway.db'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql sqlite:///oslo_norway.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'oslo_norway.osm'\n",
    "DATA_PATH = 'stovner.osm'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 376 ms, sys: 12 ms, total: 388 ms\n",
      "Wall time: 415 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "\n",
    "node_counts = defaultdict(int)\n",
    "for event, node in ET.iterparse(DATA_PATH, events=('start',)):\n",
    "    node_counts[node.tag] += 1\n",
    "        \n",
    "node_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'bounds': 1,\n",
       "             'member': 16509,\n",
       "             'nd': 36455,\n",
       "             'node': 32632,\n",
       "             'osm': 1,\n",
       "             'relation': 134,\n",
       "             'tag': 30977,\n",
       "             'way': 4837})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n%%time\\nfrom collections import defaultdict\\n\\nnode_counts = defaultdict(int)\\nfor event, node in ET.iterparse(DATA_PATH, events=('start',)):\\n    if elem.tag == 'way':\\n        for tag in elem.iter('tag'):\\n            if is_street_name(tag):\\n                audit_street_type(street_types, tag.attrib['v'])\\npprint.pprint(dict(street_types))        \\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "from collections import defaultdict\n",
    "\n",
    "node_counts = defaultdict(int)\n",
    "for event, node in ET.iterparse(DATA_PATH, events=('start',)):\n",
    "    if elem.tag == 'way':\n",
    "        for tag in elem.iter('tag'):\n",
    "            if is_street_name(tag):\n",
    "                audit_street_type(street_types, tag.attrib['v'])\n",
    "pprint.pprint(dict(street_types))        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 14075, 'lower_colon': 16764, 'other': 138, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "KEY_TYPES = [\n",
    "    ('problemchars', problemchars),\n",
    "    ('lower_colon', lower_colon),\n",
    "    ('lower', lower),\n",
    "    ('other', re.compile(r'.*'))\n",
    "]\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        k = element.attrib['k']\n",
    "        if k is not None:\n",
    "            for key, pat in KEY_TYPES:\n",
    "                 if pat.search(k) is not None:\n",
    "                     keys[key] += 1\n",
    "                     break\n",
    "    return keys\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename, events=('start',)):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "\n",
    "keys = process_map(DATA_PATH)\n",
    "pprint.pprint(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'673a',\n",
      " 'ArneH',\n",
      " 'BRoboMan',\n",
      " 'BiIbo',\n",
      " 'Bjørn Larsen',\n",
      " 'BjørnN',\n",
      " 'Bobkare',\n",
      " 'Competizione',\n",
      " 'EOE',\n",
      " 'Einar Bøhn',\n",
      " 'EirikGr',\n",
      " 'Entur AS | Jan Brekke',\n",
      " 'Entur AS | Johan Wiklund',\n",
      " 'Essin',\n",
      " 'FredrikLindseth',\n",
      " 'Fudgiepoos',\n",
      " 'Gazer75',\n",
      " 'Gazer75_import',\n",
      " 'Geirkr',\n",
      " 'Gnonthgol_import',\n",
      " 'Gustav F',\n",
      " 'HansHE',\n",
      " 'HelgeO',\n",
      " 'Hjart',\n",
      " 'Håkon',\n",
      " 'Kai Stian',\n",
      " 'KonTur',\n",
      " 'Kurtn',\n",
      " 'LA2',\n",
      " 'LilleLudo',\n",
      " 'NKA',\n",
      " 'Noen',\n",
      " 'Pizzabolle',\n",
      " 'Polarbear',\n",
      " 'RaBalder',\n",
      " 'Ramseslegrand',\n",
      " 'Reitstoen',\n",
      " 'Rian76',\n",
      " 'Skywave',\n",
      " 'T2norway',\n",
      " 'Thpe',\n",
      " 'Tompro',\n",
      " 'Tractor',\n",
      " 'Tronikon',\n",
      " \"Turleder'n\",\n",
      " 'Vedeler',\n",
      " 'WJtW',\n",
      " 'ZorroIII',\n",
      " 'abel801',\n",
      " 'aighes',\n",
      " 'aytfadc',\n",
      " 'brunnen',\n",
      " 'cgu66',\n",
      " 'dkart',\n",
      " 'eiriks',\n",
      " 'gormur',\n",
      " 'haakonst',\n",
      " 'hecktor',\n",
      " 'hofoen',\n",
      " 'jejacobsen',\n",
      " 'kao',\n",
      " 'kerosin',\n",
      " 'km2bp',\n",
      " 'knuthaug',\n",
      " 'kristaga',\n",
      " 'landfahrer',\n",
      " 'michalzz',\n",
      " 'oddbear',\n",
      " 'opani',\n",
      " 'oyvind',\n",
      " 'piligab',\n",
      " 'pizzaiolo',\n",
      " 'polarbear42',\n",
      " 'qwem',\n",
      " 'rmikke',\n",
      " 'roemcke',\n",
      " 'rubund',\n",
      " 'rubund_import',\n",
      " 'tibnor',\n",
      " 'tunapeter',\n",
      " 'tusvik',\n",
      " 'ulfl',\n",
      " 'venerdi',\n",
      " 'vibrog',\n",
      " 'wheelmap_android',\n",
      " 'zidel',\n",
      " 'Øystein Bjørndal',\n",
      " 'Øystein Bjørndal_import'}\n"
     ]
    }
   ],
   "source": [
    "def get_user(element):\n",
    "    return\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename, events=('start',)):\n",
    "        if 'user' in element.attrib:\n",
    "            users.add(element.attrib['user'])\n",
    "        \n",
    "    return users\n",
    "\n",
    "users = process_map(DATA_PATH)\n",
    "pprint.pprint(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bekkevollveien': {'Bekkevollveien'},\n",
      " 'Bergtunveien': {'Bergtunveien'},\n",
      " 'Bikuben': {'Bikuben'},\n",
      " 'Bjerkeliveien': {'Bjerkeliveien'},\n",
      " 'Bjørnheimveien': {'Bjørnheimveien'},\n",
      " 'Brolandsveien': {'Brolandsveien'},\n",
      " 'Ellingsrudveien': {'Ellingsrudveien'},\n",
      " 'Enebostubben': {'Enebostubben'},\n",
      " 'Eneboveien': {'Eneboveien'},\n",
      " 'Fjellstuveien': {'Fjellstuveien'},\n",
      " 'Folkvangveien': {'Folkvangveien'},\n",
      " 'Fredheimveien': {'Fredheimveien'},\n",
      " 'Granliveien': {'Granliveien'},\n",
      " 'Hagastubben': {'Hagastubben'},\n",
      " 'Hagaveien': {'Hagaveien'},\n",
      " 'Haugenstua': {'Haugenstua'},\n",
      " 'Haugenstuveien': {'Haugenstuveien'},\n",
      " 'Hornfjellveien': {'Hornfjellveien'},\n",
      " 'Høybråten': {'Høybråten'},\n",
      " 'Høybråtenstien': {'Høybråtenstien'},\n",
      " 'Høybråtenveien': {'Høybråtenveien'},\n",
      " 'Idrettsveien': {'Idrettsveien'},\n",
      " 'Kleiva': {'Kleiva'},\n",
      " 'Kringveien': {'Kringveien'},\n",
      " 'Langlibakken': {'Langlibakken'},\n",
      " 'Linjebakken': {'Linjebakken'},\n",
      " 'Linjeveien': {'Linjeveien'},\n",
      " 'Lundåsveien': {'Lundåsveien'},\n",
      " 'Lyngtrekket': {'Lyngtrekket'},\n",
      " 'Myrbakkveien': {'Myrbakkveien'},\n",
      " 'Myrdalveien': {'Myrdalveien'},\n",
      " 'Nuggerudveien': {'Nuggerudveien'},\n",
      " 'Nybrottveien': {'Nybrottveien'},\n",
      " 'Nybyggerveien': {'Nybyggerveien'},\n",
      " 'Skanseveien': {'Skanseveien'},\n",
      " 'Skoglistubben': {'Skoglistubben'},\n",
      " 'Skogstien': {'Skogstien'},\n",
      " 'Smiuvegen': {'Smiuvegen'},\n",
      " 'Sportsstien': {'Sportsstien'},\n",
      " 'Starveien': {'Starveien'},\n",
      " 'Stigenga': {'Stigenga'},\n",
      " 'Stovnerbakken': {'Stovnerbakken'},\n",
      " 'Stovnerfaret': {'Stovnerfaret'},\n",
      " 'Stovnerveien': {'Stovnerveien'},\n",
      " 'Tangerudbakken': {'Tangerudbakken'},\n",
      " 'Tangerudveien': {'Tangerudveien'},\n",
      " 'Tjonerudbakken': {'Tjonerudbakken'},\n",
      " 'Tjonerudveien': {'Tjonerudveien'},\n",
      " 'Trestegveien': {'Trestegveien'},\n",
      " 'Vardeheimveien': {'Vardeheimveien'},\n",
      " 'allé': {'Solbakken allé'},\n",
      " 'bussholdeplass': {'Høybråten park/ bussholdeplass',\n",
      "                    'Karihaugveien v/Folkvangveien bussholdeplass'},\n",
      " 'vei': {'Bredes vei',\n",
      "         'Garver Ytteborgs vei',\n",
      "         'Idas vei',\n",
      "         'Johnny Svorkmos vei',\n",
      "         'Jorines vei',\n",
      "         'Karl Andersens vei',\n",
      "         'Kristoffer Robins vei',\n",
      "         'Olaus Fjørtofts vei',\n",
      "         'Ole Brumms vei',\n",
      "         'Ruths vei',\n",
      "         'Sigurd Weisæths vei',\n",
      "         'Tante Ulrikkes vei',\n",
      "         'Torbjørns vei',\n",
      "         'Østre Aker vei'}}\n",
      "Nybrottveien => Nybrottveien\n",
      "Skogstien => Skogstien\n",
      "Idas vei => Idas vei\n",
      "Garver Ytteborgs vei => Garver Ytteborgs vei\n",
      "Torbjørns vei => Torbjørns vei\n",
      "Ruths vei => Ruths vei\n",
      "Bredes vei => Bredes vei\n",
      "Karl Andersens vei => Karl Andersens vei\n",
      "Østre Aker vei => Østre Aker vei\n",
      "Sigurd Weisæths vei => Sigurd Weisæths vei\n",
      "Jorines vei => Jorines vei\n",
      "Johnny Svorkmos vei => Johnny Svorkmos vei\n",
      "Tante Ulrikkes vei => Tante Ulrikkes vei\n",
      "Olaus Fjørtofts vei => Olaus Fjørtofts vei\n",
      "Ole Brumms vei => Ole Brumms vei\n",
      "Kristoffer Robins vei => Kristoffer Robins vei\n",
      "Smiuvegen => Smiuvegen\n",
      "Langlibakken => Langlibakken\n",
      "Sportsstien => Sportsstien\n",
      "Bekkevollveien => Bekkevollveien\n",
      "Lundåsveien => Lundåsveien\n",
      "Brolandsveien => Brolandsveien\n",
      "Stovnerbakken => Stovnerbakken\n",
      "Haugenstua => Haugenstua\n",
      "Nybyggerveien => Nybyggerveien\n",
      "Stovnerveien => Stovnerveien\n",
      "Solbakken allé => Solbakken allé\n",
      "Granliveien => Granliveien\n",
      "Hornfjellveien => Hornfjellveien\n",
      "Skoglistubben => Skoglistubben\n",
      "Ellingsrudveien => Ellingsrudveien\n",
      "Myrbakkveien => Myrbakkveien\n",
      "Nuggerudveien => Nuggerudveien\n",
      "Eneboveien => Eneboveien\n",
      "Tangerudbakken => Tangerudbakken\n",
      "Vardeheimveien => Vardeheimveien\n",
      "Høybråtenstien => Høybråtenstien\n",
      "Kleiva => Kleiva\n",
      "Høybråten => Høybråten\n",
      "Tangerudveien => Tangerudveien\n",
      "Enebostubben => Enebostubben\n",
      "Starveien => Starveien\n",
      "Karihaugveien v/Folkvangveien bussholdeplass => Karihaugveien v/Folkvangveien bussholdeplass\n",
      "Høybråten park/ bussholdeplass => Høybråten park/ bussholdeplass\n",
      "Linjebakken => Linjebakken\n",
      "Hagaveien => Hagaveien\n",
      "Kringveien => Kringveien\n",
      "Folkvangveien => Folkvangveien\n",
      "Haugenstuveien => Haugenstuveien\n",
      "Bikuben => Bikuben\n",
      "Idrettsveien => Idrettsveien\n",
      "Tjonerudveien => Tjonerudveien\n",
      "Fredheimveien => Fredheimveien\n",
      "Høybråtenveien => Høybråtenveien\n",
      "Myrdalveien => Myrdalveien\n",
      "Stigenga => Stigenga\n",
      "Lyngtrekket => Lyngtrekket\n",
      "Bergtunveien => Bergtunveien\n",
      "Tjonerudbakken => Tjonerudbakken\n",
      "Fjellstuveien => Fjellstuveien\n",
      "Linjeveien => Linjeveien\n",
      "Stovnerfaret => Stovnerfaret\n",
      "Bjørnheimveien => Bjørnheimveien\n",
      "Hagastubben => Hagastubben\n",
      "Skanseveien => Skanseveien\n",
      "Trestegveien => Trestegveien\n",
      "Bjerkeliveien => Bjerkeliveien\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Your task in this exercise has two steps:\n",
    "\n",
    "- audit the OSMFILE and change the variable 'mapping' to reflect the changes needed to fix \n",
    "    the unexpected street types to the appropriate ones in the expected list.\n",
    "    You have to add mappings only for the actual problems you find in this OSMFILE,\n",
    "    not a generalized solution, since that may and will depend on the particular area you are auditing.\n",
    "- write the update_name function, to actually fix the street name.\n",
    "    The function takes a string with street name as an argument and should return the fixed name\n",
    "    We have provided a simple test so that you see what exactly is expected\n",
    "\"\"\"\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"example.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd.\": \"Road\"\n",
    "            }\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    suffix = name.split(' ')[-1]\n",
    "    if suffix in mapping:\n",
    "        return name.replace(suffix, mapping[suffix])\n",
    "    return name\n",
    "\n",
    "\n",
    "def test():\n",
    "    st_types = audit(DATA_PATH)\n",
    "    pprint.pprint(dict(st_types))\n",
    "\n",
    "    for st_type, ways in st_types.items():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print(name, \"=>\", better_name)\n",
    "            if name == \"West Lexington St.\":\n",
    "                assert better_name == \"West Lexington Street\"\n",
    "            if name == \"Baldwin Rd.\":\n",
    "                assert better_name == \"Baldwin Road\"\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCHEMA = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "After auditing is complete the next step is to prepare the data to be inserted into a SQL database.\n",
    "To do so you will parse the elements in the OSM XML file, transforming them from document format to\n",
    "tabular format, thus making it possible to write to .csv files.  These csv files can then easily be\n",
    "imported to a SQL database as tables.\n",
    "\n",
    "The process for this transformation is as follows:\n",
    "- Use iterparse to iteratively step through each top level element in the XML\n",
    "- Shape each element into several data structures using a custom function\n",
    "- Utilize a schema and validation library to ensure the transformed data is in the correct format\n",
    "- Write each data structure to the appropriate .csv files\n",
    "\n",
    "We've already provided the code needed to load the data, perform iterative parsing and write the\n",
    "output to csv files. Your task is to complete the shape_element function that will transform each\n",
    "element into the correct format. To make this process easier we've already defined a schema (see\n",
    "the schema.py file in the last code tab) for the .csv files and the eventual tables. Using the \n",
    "cerberus library we can validate the output against this schema to ensure it is correct.\n",
    "\n",
    "## Shape Element Function\n",
    "The function should take as input an iterparse Element object and return a dictionary.\n",
    "\n",
    "### If the element top level tag is \"node\":\n",
    "The dictionary returned should have the format {\"node\": .., \"node_tags\": ...}\n",
    "\n",
    "The \"node\" field should hold a dictionary of the following top level node attributes:\n",
    "- id\n",
    "- user\n",
    "- uid\n",
    "- version\n",
    "- lat\n",
    "- lon\n",
    "- timestamp\n",
    "- changeset\n",
    "All other attributes can be ignored\n",
    "\n",
    "The \"node_tags\" field should hold a list of dictionaries, one per secondary tag. Secondary tags are\n",
    "child tags of node which have the tag name/type: \"tag\". Each dictionary should have the following\n",
    "fields from the secondary tag attributes:\n",
    "- id: the top level node id attribute value\n",
    "- key: the full tag \"k\" attribute value if no colon is present or the characters after the colon if one is.\n",
    "- value: the tag \"v\" attribute value\n",
    "- type: either the characters before the colon in the tag \"k\" value or \"regular\" if a colon\n",
    "        is not present.\n",
    "\n",
    "Additionally,\n",
    "\n",
    "- if the tag \"k\" value contains problematic characters, the tag should be ignored\n",
    "- if the tag \"k\" value contains a \":\" the characters before the \":\" should be set as the tag type\n",
    "  and characters after the \":\" should be set as the tag key\n",
    "- if there are additional \":\" in the \"k\" value they and they should be ignored and kept as part of\n",
    "  the tag key. For example:\n",
    "\n",
    "  <tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "  should be turned into\n",
    "  {'id': 12345, 'key': 'street:name', 'value': 'Lincoln', 'type': 'addr'}\n",
    "\n",
    "- If a node has no secondary tags then the \"node_tags\" field should just contain an empty list.\n",
    "\n",
    "The final return value for a \"node\" element should look something like:\n",
    "\n",
    "{'node': {'id': 757860928,\n",
    "          'user': 'uboot',\n",
    "          'uid': 26299,\n",
    "       'version': '2',\n",
    "          'lat': 41.9747374,\n",
    "          'lon': -87.6920102,\n",
    "          'timestamp': '2010-07-22T16:16:51Z',\n",
    "      'changeset': 5288876},\n",
    " 'node_tags': [{'id': 757860928,\n",
    "                'key': 'amenity',\n",
    "                'value': 'fast_food',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'cuisine',\n",
    "                'value': 'sausage',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'name',\n",
    "                'value': \"Shelly's Tasty Freeze\",\n",
    "                'type': 'regular'}]}\n",
    "\n",
    "### If the element top level tag is \"way\":\n",
    "The dictionary should have the format {\"way\": ..., \"way_tags\": ..., \"way_nodes\": ...}\n",
    "\n",
    "The \"way\" field should hold a dictionary of the following top level way attributes:\n",
    "- id\n",
    "-  user\n",
    "- uid\n",
    "- version\n",
    "- timestamp\n",
    "- changeset\n",
    "\n",
    "All other attributes can be ignored\n",
    "\n",
    "The \"way_tags\" field should again hold a list of dictionaries, following the exact same rules as\n",
    "for \"node_tags\".\n",
    "\n",
    "Additionally, the dictionary should have a field \"way_nodes\". \"way_nodes\" should hold a list of\n",
    "dictionaries, one for each nd child tag.  Each dictionary should have the fields:\n",
    "- id: the top level element (way) id\n",
    "- node_id: the ref attribute value of the nd tag\n",
    "- position: the index starting at 0 of the nd tag i.e. what order the nd tag appears within\n",
    "            the way element\n",
    "\n",
    "The final return value for a \"way\" element should look something like:\n",
    "\n",
    "{'way': {'id': 209809850,\n",
    "         'user': 'chicago-buildings',\n",
    "         'uid': 674454,\n",
    "         'version': '1',\n",
    "         'timestamp': '2013-03-13T15:58:04Z',\n",
    "         'changeset': 15353317},\n",
    " 'way_nodes': [{'id': 209809850, 'node_id': 2199822281, 'position': 0},\n",
    "               {'id': 209809850, 'node_id': 2199822390, 'position': 1},\n",
    "               {'id': 209809850, 'node_id': 2199822392, 'position': 2},\n",
    "               {'id': 209809850, 'node_id': 2199822369, 'position': 3},\n",
    "               {'id': 209809850, 'node_id': 2199822370, 'position': 4},\n",
    "               {'id': 209809850, 'node_id': 2199822284, 'position': 5},\n",
    "               {'id': 209809850, 'node_id': 2199822281, 'position': 6}],\n",
    " 'way_tags': [{'id': 209809850,\n",
    "               'key': 'housenumber',\n",
    "               'type': 'addr',\n",
    "               'value': '1412'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street',\n",
    "               'type': 'addr',\n",
    "               'value': 'West Lexington St.'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:name',\n",
    "               'type': 'addr',\n",
    "               'value': 'Lexington'},\n",
    "              {'id': '209809850',\n",
    "               'key': 'street:prefix',\n",
    "               'type': 'addr',\n",
    "               'value': 'West'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:type',\n",
    "               'type': 'addr',\n",
    "               'value': 'Street'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building',\n",
    "               'type': 'regular',\n",
    "               'value': 'yes'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'levels',\n",
    "               'type': 'building',\n",
    "               'value': '1'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building_id',\n",
    "               'type': 'chicago',\n",
    "               'value': '366409'}]}\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import cerberus\n",
    "\n",
    "OSM_PATH = \"example.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "DEFAULT_TAG_TYPE = 'regular'\n",
    "\n",
    "def gather_attribs(el, attr_schema):\n",
    "    res = {}\n",
    "    for k, v in attr_schema.items():\n",
    "        if k in el.attrib:\n",
    "            val = el.attrib[k]\n",
    "            if 'coerce' in v:\n",
    "                res[k] = (v['coerce'])(val)\n",
    "            else:\n",
    "                res[k] = val\n",
    "    return res\n",
    "\n",
    "\n",
    "def gather_tags(el, parent_attr):\n",
    "    parent_id = parent_attr['id']\n",
    "    for tag in el.iter(\"tag\"):\n",
    "        if 'k' not in tag.attrib or 'v' not in tag.attrib:\n",
    "            continue\n",
    "        k = tag.attrib['k']\n",
    "        if PROBLEMCHARS.search(k) is not None:\n",
    "            continue\n",
    "        parts = k.split(':', 1)\n",
    "        if len(parts) > 1:\n",
    "            tag_type = parts[0]\n",
    "            tag_key = parts[1]\n",
    "        else:\n",
    "            tag_type = DEFAULT_TAG_TYPE\n",
    "            tag_key = k\n",
    "        yield {'id': parent_id, \n",
    "               'key': tag_key, \n",
    "               'type': tag_type, \n",
    "               'value': tag.attrib['v']}\n",
    "\n",
    "\n",
    "def gather_way_nodes(el, parent_attr):\n",
    "    parent_id = parent_attr['id']\n",
    "    position = 0\n",
    "    for tag in el.iter('nd'):\n",
    "        if 'ref' not in tag.attrib:\n",
    "            continue\n",
    "        try:\n",
    "            yield {'id': parent_id, \n",
    "                   'node_id': int(tag.attrib['ref']), \n",
    "                   'position': position}\n",
    "            position += 1\n",
    "        except ValueError:\n",
    "            # skip node with invalid reference\n",
    "            pass\n",
    "            \n",
    "def shape_element(element, \n",
    "                  node_attr_fields=NODE_FIELDS, \n",
    "                  way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, \n",
    "                  default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        node_attribs = gather_attribs(element, SCHEMA['node']['schema'])\n",
    "        tags = list(gather_tags(element, node_attribs))\n",
    "        return {'node': node_attribs, \n",
    "                'node_tags': tags}\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        way_attribs = gather_attribs(element, SCHEMA['way']['schema'])\n",
    "        way_nodes = list(gather_way_nodes(element, way_attribs))\n",
    "        tags = list(gather_tags(element, way_attribs))\n",
    "        return {'way': way_attribs, \n",
    "                'way_nodes': way_nodes, \n",
    "                'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(iter(validator.errors.items()))\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: v for k, v in row.items()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "process_map(DATA_PATH, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
